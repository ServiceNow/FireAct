# Fine-tune


## Data

See [Fine-tune Data](https://github.com/anchen1011/FireAct/tree/main/data)

## Training

#### LoRA

#### Full Model

#### GPT

See [OpenAI Fine-tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)

## References
1. Our Llama full model training code is based on [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)
2. Our Llama LoRA training code is based on [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)
3. Our GPT fine-tuning code is based on [anchen1011/chatgpt-finetune-ui](https://github.com/anchen1011/chatgpt-finetune-ui/)
